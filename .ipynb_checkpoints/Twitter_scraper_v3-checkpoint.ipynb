{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T11:34:36.550766Z",
     "start_time": "2019-03-06T11:34:26.062075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this for followers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    " \n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://allofyourbases.com/2018/01/16/mining-twitter-with-selenium/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T11:34:39.372729Z",
     "start_time": "2019-03-06T11:34:36.552770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run these function definitions\n",
    "def scrape_followers(driver):\n",
    "    # initial wait for the search results to load\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    try:\n",
    "        # wait until the first search result is found. Search results will be tweets, which are html list items and have the class='data-item-id':\n",
    "        wait.until(EC.visibility_of_element_located(\n",
    "            (By.CSS_SELECTOR, \"div[data-user-id]\")))\n",
    "\n",
    "        # scroll down to the last tweet until there are no more tweets:\n",
    "        while True:\n",
    "\n",
    "            # extract all the tweets:\n",
    "            followers = driver.find_elements_by_css_selector(\n",
    "                \"div[data-user-id]\")\n",
    "\n",
    "            # find number of visible tweets:\n",
    "            number_of_followers = len(followers)\n",
    "\n",
    "            # keep scrolling:\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].scrollIntoView();\", followers[-1])\n",
    "\n",
    "            try:\n",
    "                # wait for more tweets to be visible:\n",
    "                wait.until(wait_for_more_than_n_elements_to_be_present(\n",
    "                    (By.CSS_SELECTOR, \"div[data-user-id]\"), number_of_followers))\n",
    "\n",
    "            except TimeoutException:\n",
    "                # if no more are visible the \"wait.until\" call will timeout. Catch the exception and exit the while loop:\n",
    "                break\n",
    "\n",
    "        # extract the html for the whole lot:\n",
    "        page_source = driver.page_source\n",
    "\n",
    "    except TimeoutException:\n",
    "\n",
    "        # if there are no search results then the \"wait.until\" call in the first \"try\" statement will never happen and it will time out. So we catch that exception and return no html.\n",
    "        page_source = None\n",
    "\n",
    "    return page_source\n",
    "\n",
    "\n",
    "def extract_followers(page_source):\n",
    "\n",
    "    soup = bs(page_source, 'lxml')\n",
    "\n",
    "    followers = []\n",
    "\n",
    "    for div in soup.find_all(\"a\", class_='fullname'):\n",
    "        follower = {\n",
    "            'screen_name': div['href'][1:],\n",
    "            'full_name': div.get_text().strip()\n",
    "        }\n",
    "\n",
    "        followers.append(follower)\n",
    "\n",
    "    return followers[1:]\n",
    "\n",
    "\n",
    "def init_driver():\n",
    "\n",
    "    # do not load images\n",
    "    chromeOptions = webdriver.ChromeOptions()\n",
    "    prefs = {'profile.managed_default_content_settings.images':2}\n",
    "    chromeOptions.add_experimental_option(\"prefs\", prefs)\n",
    "    \n",
    "    # initiate the driver:\n",
    "    driver = webdriver.Chrome(\n",
    "        '/Users/fernandojavier/Desktop/MSDS/Portfolio/Protest Spread in Twitter/chromedriver', \n",
    "        chrome_options=chromeOptions)\n",
    "    # set a default wait time for the browser [5 seconds here]:\n",
    "    driver.wait = WebDriverWait(driver, 5)\n",
    "\n",
    "    return driver\n",
    "\n",
    "\n",
    "def close_driver(driver):\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def login_twitter(driver, username, password):\n",
    "\n",
    "    # open the web page in the browser:\n",
    "    driver.get(\"https://twitter.com/login\")\n",
    "\n",
    "    # find the boxes for username and password\n",
    "    username_field = driver.find_element_by_class_name(\"js-username-field\")\n",
    "    password_field = driver.find_element_by_class_name(\"js-password-field\")\n",
    "\n",
    "    # enter your username:\n",
    "    username_field.send_keys(username)\n",
    "    driver.implicitly_wait(1)\n",
    "\n",
    "    # enter your password:\n",
    "    password_field.send_keys(password)\n",
    "    driver.implicitly_wait(1)\n",
    "\n",
    "    # click the \"Log In\" button:\n",
    "    driver.find_element_by_class_name(\"EdgeButtom--medium\").click()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "class wait_for_more_than_n_elements_to_be_present(object):\n",
    "    def __init__(self, locator, count):\n",
    "        self.locator = locator\n",
    "        self.count = count\n",
    "\n",
    "    def __call__(self, driver):\n",
    "        try:\n",
    "            elements = EC._find_elements(driver, self.locator)\n",
    "            return len(elements) > self.count\n",
    "        except StaleElementReferenceException:\n",
    "            return False\n",
    "\n",
    "\n",
    "def search_twitter(driver, query):\n",
    "\n",
    "    # wait until the search box has loaded:\n",
    "    box = driver.wait.until(EC.presence_of_element_located((By.NAME, \"q\")))\n",
    "\n",
    "    # find the search box in the html:\n",
    "    driver.find_element_by_name(\"q\").clear()\n",
    "\n",
    "    # enter your search string in the search box:\n",
    "    box.send_keys(query)\n",
    "\n",
    "    # submit the query (like hitting return):\n",
    "    box.submit()\n",
    "\n",
    "    # initial wait for the search results to load\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "\n",
    "    try:\n",
    "        # wait until the first search result is found. Search results will be tweets, which are html list items and have the class='data-item-id':\n",
    "        wait.until(EC.visibility_of_element_located(\n",
    "            (By.CSS_SELECTOR, \"li[data-item-id]\")))\n",
    "\n",
    "        # scroll down to the last tweet until there are no more tweets:\n",
    "        while True:\n",
    "\n",
    "            # extract all the tweets:\n",
    "            tweets = driver.find_elements_by_css_selector(\"li[data-item-id]\")\n",
    "\n",
    "            # find number of visible tweets:\n",
    "            number_of_tweets = len(tweets)\n",
    "\n",
    "            # keep scrolling:\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", tweets[-1])\n",
    "\n",
    "            try:\n",
    "                # wait for more tweets to be visible:\n",
    "                wait.until(wait_for_more_than_n_elements_to_be_present(\n",
    "                    (By.CSS_SELECTOR, \"li[data-item-id]\"), number_of_tweets))\n",
    "\n",
    "            except TimeoutException:\n",
    "                # if no more are visible the \"wait.until\" call will timeout. Catch the exception and exit the while loop:\n",
    "                break\n",
    "\n",
    "        # extract the html for the whole lot:\n",
    "        page_source = driver.page_source\n",
    "\n",
    "    except TimeoutException:\n",
    "\n",
    "        # if there are no search results then the \"wait.until\" call in the first \"try\" statement will never happen and it will time out. So we catch that exception and return no html.\n",
    "        page_source = None\n",
    "\n",
    "    return page_source\n",
    "\n",
    "\n",
    "def extract_tweets(page_source, driver):\n",
    "\n",
    "    soup = bs(page_source, 'lxml')\n",
    "\n",
    "    tweets = []\n",
    "    for li in soup.find_all(\"li\", class_='js-stream-item'):\n",
    "\n",
    "        # If our li doesn't have a tweet-id, we skip it as it's not going to be a tweet.\n",
    "        if 'data-item-id' not in li.attrs:\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            tweet = {\n",
    "                'tweet_id': li['data-item-id'],\n",
    "                'parent_tweet_id': None,\n",
    "                'text': None,\n",
    "                'user_id': None,\n",
    "                'user_screen_name': None,\n",
    "                'user_name': None,\n",
    "                'retweets': 0,\n",
    "                'likes': 0,\n",
    "                'replies': 0,\n",
    "                'timestamp': 0,\n",
    "                'date': '',\n",
    "                'reply': 0,\n",
    "                'retweet': 0\n",
    "            }\n",
    "\n",
    "            # Tweet Text\n",
    "            text_p = li.find(\"p\", class_=\"tweet-text\")\n",
    "            if text_p is not None:\n",
    "                tweet['text'] = text_p.get_text()\n",
    "\n",
    "            # Tweet User ID, User Screen Name, User Name\n",
    "            user_details_div = li.find(\"div\", class_=\"tweet\")\n",
    "            if user_details_div is not None:\n",
    "                tweet['user_id'] = user_details_div['data-user-id']\n",
    "                tweet['user_screen_name'] = user_details_div['data-screen-name']\n",
    "                tweet['user_name'] = user_details_div['data-name']\n",
    "\n",
    "            # Tweet Retweets\n",
    "            retweet_span = li.select(\n",
    "                \"span.ProfileTweet-action--retweet > span.ProfileTweet-actionCount\")\n",
    "            if retweet_span is not None and len(retweet_span) > 0:\n",
    "                tweet['retweets'] = int(\n",
    "                    retweet_span[0]['data-tweet-stat-count'])\n",
    "\n",
    "            # Tweet Likes\n",
    "            like_span = li.select(\n",
    "                \"span.ProfileTweet-action--favorite > span.ProfileTweet-actionCount\")\n",
    "            if like_span is not None and len(like_span) > 0:\n",
    "                tweet['likes'] = int(like_span[0]['data-tweet-stat-count'])\n",
    "\n",
    "            # Tweet Replies\n",
    "            reply_span = li.select(\n",
    "                \"span.ProfileTweet-action--reply > span.ProfileTweet-actionCount\")\n",
    "            if reply_span is not None and len(reply_span) > 0:\n",
    "                tweet['replies'] = int(reply_span[0]['data-tweet-stat-count'])\n",
    "\n",
    "            date_span = li.find(\"span\", class_=\"js-short-timestamp\")\n",
    "            if date_span is not None:\n",
    "                tweet['timestamp'] = date_span['data-time']\n",
    "                tweet['date'] = datetime.utcfromtimestamp(\n",
    "                    int(tweet['timestamp'])\n",
    "                ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            tweets.append(tweet)\n",
    "\n",
    "            driver.execute_script(\n",
    "                \"document.getElementById('\" +\n",
    "                str(li['id']) +\n",
    "                \"').querySelector('.tweet').click()\")\n",
    "\n",
    "            wait = WebDriverWait(driver, 2)\n",
    "\n",
    "            try:\n",
    "                # wait until the first search result is found. Search results will be tweets, which are html list items and have the class='data-item-id':\n",
    "                wait.until(EC.visibility_of_element_located(\n",
    "                    (By.CSS_SELECTOR, \"div[data-has-parent-tweet]\")))\n",
    "\n",
    "                # scroll down to the last tweet until there are no more tweets:\n",
    "                while True:\n",
    "\n",
    "                    # extract all the tweets:\n",
    "                    replies = driver.find_elements_by_css_selector(\n",
    "                        \"div[data-has-parent-tweet]\")\n",
    "\n",
    "                    # find number of visible tweets:\n",
    "                    number_of_replies = len(replies)\n",
    "\n",
    "                    if number_of_replies == 0:\n",
    "                        break\n",
    "\n",
    "                    # keep scrolling:\n",
    "                    try:\n",
    "\n",
    "                        driver.execute_script(\n",
    "                            \"arguments[0].scrollIntoView();\", replies[-1])\n",
    "\n",
    "                    except Exception:\n",
    "                        break\n",
    "\n",
    "                    try:\n",
    "                        # wait for more tweets to be visible:\n",
    "                        wait.until(wait_for_more_than_n_elements_to_be_present(\n",
    "                            (By.CSS_SELECTOR, \"div[data-has-parent-tweet]\"), number_of_replies))\n",
    "\n",
    "                    except TimeoutException:\n",
    "                        # if no more are visible the \"wait.until\" call will timeout. Catch the exception and exit the while loop:\n",
    "                        break\n",
    "\n",
    "                # extract the html for the whole lot:\n",
    "                page_source_replies = driver.page_source\n",
    "\n",
    "            except TimeoutException:\n",
    "\n",
    "                # if there are no search results then the \"wait.until\" call in the first \"try\" statement will never happen and it will time out. So we catch that exception and return no html.\n",
    "                page_source_replies = None\n",
    "\n",
    "            soup_replies = bs(page_source_replies, 'lxml')\n",
    "\n",
    "            for div in soup_replies.find_all(\"div\", class_='permalink-descendant-tweet'):\n",
    "\n",
    "                # If our li doesn't have a tweet-id, we skip it as it's not going to be a tweet.\n",
    "                if 'data-item-id' not in div.attrs:\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    reply = {\n",
    "                        'tweet_id': div['data-item-id'],\n",
    "                        'parent_tweet_id': li['data-item-id'],\n",
    "                        'text': None,\n",
    "                        'user_id': div['data-user-id'],\n",
    "                        'user_screen_name': div['data-screen-name'],\n",
    "                        'user_name': div['data-name'],\n",
    "                        'retweets': 0,\n",
    "                        'likes': 0,\n",
    "                        'replies': 0,\n",
    "                        'timestamp': 0,\n",
    "                        'date': '',\n",
    "                        'reply': 1,\n",
    "                        'retweet': 0\n",
    "                    }\n",
    "\n",
    "                    # Tweet Text\n",
    "                    text_p_reply = div.find(\"p\", class_=\"tweet-text\")\n",
    "                    if text_p_reply is not None:\n",
    "                        reply['text'] = text_p_reply.get_text()\n",
    "\n",
    "                    # Tweet Retweets\n",
    "                    retweet_span = div.select(\n",
    "                        \"div.ProfileTweet-action--retweet span.ProfileTweet-actionCountForPresentation\")\n",
    "                    if retweet_span is not None and len(retweet_span) > 0 and retweet_span[0].get_text().strip() != '':\n",
    "                        reply['retweets'] = int(\n",
    "                            retweet_span[0].get_text())\n",
    "\n",
    "                    # Tweet Likes\n",
    "                    like_span = div.select(\n",
    "                        \"div.ProfileTweet-action--favorite span.ProfileTweet-actionCountForPresentation\")\n",
    "                    if like_span is not None and len(like_span) > 0 and like_span[0].get_text().strip() != '':\n",
    "                        reply['likes'] = int(\n",
    "                            like_span[0].get_text())\n",
    "\n",
    "                    # Tweet Replies\n",
    "                    reply_span = div.select(\n",
    "                        \"div.ProfileTweet-action--reply span.ProfileTweet-actionCountForPresentation\")\n",
    "                    if reply_span is not None and len(reply_span) > 0 and reply_span[0].get_text().strip() != '':\n",
    "                        reply['replies'] = int(\n",
    "                            reply_span[0].get_text())\n",
    "\n",
    "                    date_span = div.find(\"span\", class_=\"js-short-timestamp\")\n",
    "                    if date_span is not None:\n",
    "                        reply['timestamp'] = date_span['data-time']\n",
    "                        reply['date'] = datetime.utcfromtimestamp(\n",
    "                            int(reply['timestamp'])\n",
    "                        ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                    tweets.append(reply)\n",
    "\n",
    "            try:\n",
    "                driver.execute_script(\n",
    "                    \"document.querySelector('.request-retweeted-popup').click()\")\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            time.sleep(3)\n",
    "\n",
    "            # extract the html for the whole lot:\n",
    "            page_source_retweets = driver.page_source\n",
    "\n",
    "            soup_retweets = bs(page_source_retweets, 'lxml')\n",
    "\n",
    "            for li2 in soup_retweets.find_all(attrs={\"data-item-type\": \"user\"}):\n",
    "                # If our li doesn't have a tweet-id, we skip it as it's not going to be a tweet.\n",
    "                if 'data-item-type' not in li2.attrs:\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    retweet = {\n",
    "                        'tweet_id': None,\n",
    "                        'parent_tweet_id': li['data-item-id'],\n",
    "                        'text': None,\n",
    "                        'user_id': None,\n",
    "                        'user_screen_name': None,\n",
    "                        'user_name': None,\n",
    "                        'retweets': 0,\n",
    "                        'likes': 0,\n",
    "                        'replies': 0,\n",
    "                        'timestamp': 0,\n",
    "                        'date': '',\n",
    "                        'reply': 0,\n",
    "                        'retweet': 1\n",
    "                    }\n",
    "\n",
    "                    # Tweet Text\n",
    "                    text_p_retweet = li2.find(\"p\", class_=\"bio\")\n",
    "                    if text_p_retweet is not None:\n",
    "                        retweet['text'] = text_p_retweet.get_text()\n",
    "\n",
    "                    # Tweet User ID, User Screen Name, User Name\n",
    "                    user_details_div_retweet = li2.find(\n",
    "                        \"div\", class_=\"account\")\n",
    "                    if user_details_div_retweet is not None:\n",
    "                        retweet['user_id'] = user_details_div_retweet['data-user-id']\n",
    "                        retweet['user_screen_name'] = user_details_div_retweet['data-screen-name']\n",
    "                        retweet['user_name'] = user_details_div_retweet['data-name']\n",
    "\n",
    "                    tweets.append(retweet)\n",
    "\n",
    "    return tweets\n",
    "\n",
    "\n",
    "def deduplicate_list_of_dicts(dct):\n",
    "    '''Remove multiple postings of one user as we only need 1 instance'''\n",
    "    user_list = []\n",
    "    for user in dct:\n",
    "        if user['user_screen_name'] not in user_list:\n",
    "            user_list.append(user['user_screen_name'])\n",
    "    return user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do not run this if you only want the user_following\n",
    "# # This will scrape the keyword, replace it with millionpeoplemarch, JanetNapoles or PDAFScam\n",
    "# # Replace email and password with your own\n",
    "# driver = init_driver()\n",
    "\n",
    "# login_twitter(driver, '<email>', '<password>')\n",
    "\n",
    "# hmtl = search_twitter(driver, '<keyword>')\n",
    "\n",
    "# tweets_mpm = extract_tweets(hmtl, driver)\n",
    "\n",
    "# close_driver(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T20:04:04.995098Z",
     "start_time": "2019-03-07T20:04:04.234856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this to get the distinct users from the tweets\n",
    "with open('data/new_tweets_mpm.json', 'r') as infile:\n",
    "    tweets_mpm_from_file = json.load(infile)\n",
    "    user_list_mpm = deduplicate_list_of_dicts(tweets_mpm_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this for FOLLOWERS not for FOLLOWING\n",
    "# # Run this only once ever as this only builds the tracker file\n",
    "# # If you run this again you will lose your progress tracker\n",
    "# with open('data/tweets_mpm_list.json', 'r') as outfile:\n",
    "#     json.dump(user_list_mpm, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T10:03:59.687464Z",
     "start_time": "2019-03-06T10:03:59.674367Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Run this to get FOLLOWERS so don't run if you want FOLLOWING users\n",
    "# with open('user_followers.json', 'r') as infile:\n",
    "#     user_followers = json.load(infile)\n",
    "# print(len(user_followers))\n",
    "    \n",
    "# with open('tweets_mpm_list.json', 'r') as infile:\n",
    "#     track_list = json.load(infile)\n",
    "# print(len(track_list))\n",
    "\n",
    "# for user in track_list:\n",
    "#     while True:\n",
    "#         try:\n",
    "#             driver = init_driver()\n",
    "#             login_twitter(driver, '<email>', '<password>')\n",
    "#             break\n",
    "#         except Exception:\n",
    "#             close_driver(driver)\n",
    "#             pass\n",
    "#     # open the web page in the browser:\n",
    "#     driver.get(\"https://twitter.com/\" +\n",
    "#                user + '/followers')\n",
    "#     followers_html = scrape_followers(driver)\n",
    "#     followers = extract_followers(followers_html)\n",
    "#     user_followers[user] = followers\n",
    "#     track_list = track_list[1:]\n",
    "#     with open('tweets_mpm_list.json', 'w') as outfile:\n",
    "#         json.dump(track_list, outfile)\n",
    "#     with open('user_followers.json', 'w') as outfile:\n",
    "#         json.dump(user_followers, outfile)\n",
    "#     close_driver(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T06:08:05.605962Z",
     "start_time": "2019-03-07T06:08:05.597528Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if file exists\n",
    "try:\n",
    "    with open('data/user_following.json', 'r') as infile:\n",
    "        user_following = json.load(infile)\n",
    "except:\n",
    "    # create file if theres no file yet\n",
    "    f = open(\"data/user_following.json\", \"w+\")\n",
    "    f.write(\"{}\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-08T08:58:02.146840Z",
     "start_time": "2019-03-08T08:21:16.727622Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5455\n",
      "1008\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-e2a63118d5c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m                user + '/following')\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mfollowing_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscrape_followers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-3faceab58630>\u001b[0m in \u001b[0;36mscrape_followers\u001b[0;34m(driver)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# wait until the first search result is found. Search results will be tweets, which are html list items and have the class='data-item-id':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         wait.until(EC.visibility_of_element_located(\n\u001b[0;32m----> 9\u001b[0;31m             (By.CSS_SELECTOR, \"div[data-user-id]\")))\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# scroll down to the last tweet until there are no more tweets:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/support/wait.py\u001b[0m in \u001b[0;36muntil\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_driver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/support/expected_conditions.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, driver)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_element_if_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_find_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStaleElementReferenceException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/support/expected_conditions.py\u001b[0m in \u001b[0;36m_find_element\u001b[0;34m(driver, by)\u001b[0m\n\u001b[1;32m    395\u001b[0m     if thrown.\"\"\"\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNoSuchElementException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    964\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    965\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhttplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run this to get FOLLOWING so don't run if you want FOLLOWERS users\n",
    "# Run this for FOLLOWING not for FOLLOWERS\n",
    "\n",
    "# RUN TRACKER\n",
    "with open('data/user_following.json', 'r') as infile:\n",
    "    following_mpm_from_file = json.load(infile)\n",
    "    user_following_unique = list(set(following_mpm_from_file.keys()))\n",
    "    \n",
    "to_scrape = [user for user in user_list_mpm if user not in user_following_unique]\n",
    "\n",
    "with open('data/tweets_mpm_list_following.json', 'w') as outfile:\n",
    "    json.dump(to_scrape, outfile)\n",
    "    \n",
    "    \n",
    "# SCRAPER\n",
    "\n",
    "with open('data/user_following.json', 'r') as infile:\n",
    "        user_following = json.load(infile)\n",
    "\n",
    "print(len(set(user_following)))\n",
    "\n",
    "with open('data/tweets_mpm_list_following.json', 'r') as infile:\n",
    "    track_list = json.load(infile)\n",
    "print(len(track_list))\n",
    "\n",
    "driver = init_driver()\n",
    "login_twitter(driver, 'othepjavier@gmail.com', 'TheM@trix')\n",
    "\n",
    "for user in track_list:\n",
    "    #     while True:\n",
    "    #         try:\n",
    "    #             driver = init_driver()\n",
    "    #             login_twitter(driver, 'dybrian008@gmail.com', 'Imaginebreaker12')\n",
    "    #             break\n",
    "    #         except Exception:\n",
    "    #             close_driver(driver)\n",
    "    #             pass\n",
    "    # open the web page in the browser:\n",
    "    driver.get(\"https://twitter.com/\" +\n",
    "               user + '/following')\n",
    "    try:\n",
    "        following_html = scrape_followers(driver)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        following = extract_followers(following_html)\n",
    "    except Exception:\n",
    "        track_list = track_list[1:]\n",
    "        with open('data/tweets_mpm_list_following.json', 'w') as outfile:\n",
    "            json.dump(track_list, outfile)\n",
    "        continue\n",
    "    user_following[user] = following\n",
    "    track_list = track_list[1:]\n",
    "    with open('data/tweets_mpm_list_following.json', 'w') as outfile:\n",
    "        json.dump(track_list, outfile)\n",
    "    with open('data/user_following.json', 'w') as outfile:\n",
    "        json.dump(user_following, outfile)\n",
    "    # close_driver(driver)\n",
    "close_driver(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6463 - all users"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
